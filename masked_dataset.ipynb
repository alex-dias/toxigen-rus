{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alexandre\\miniconda3\\envs\\huggingface\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\Alexandre\\miniconda3\\envs\\huggingface\\lib\\site-packages\\datasets\\load.py:2483: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.\n",
      "You can remove this warning by passing 'token=<use_auth_token>' instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "TG_data = load_dataset(\"skg/toxigen-data\", name=\"train\", use_auth_token=True) # 250k training examples\n",
    "TG_annotations = load_dataset(\"skg/toxigen-data\", name=\"annotated\", use_auth_token=True) # Human study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.DataFrame(TG_data[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"masked\"] = \"\"\n",
    "dataset[\"nsubj\"] = \"\"\n",
    "dataset[\"preds\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alexandre\\miniconda3\\envs\\huggingface\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "unmasker = pipeline('fill-mask', model='roberta-large', tokenizer='roberta-large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for group in ['middle_east']:\n",
    "\n",
    "    dataset_temp = dataset.loc[dataset['group'] == group]\n",
    "\n",
    "    for index, row in dataset_temp.iterrows():\n",
    "        cnt = 0\n",
    "        # Access row values using row['column_name']\n",
    "        doc = nlp(row['generation'])\n",
    "        for t in doc:\n",
    "            if t.dep_ == \"nsubj\" and cnt == 0:\n",
    "                dataset_temp.at[index, \"nsubj\"] = t.text\n",
    "                masked_str = dataset_temp.at[index, \"generation\"].replace(t.text, \"<mask>\", 1)\n",
    "                dataset_temp.at[index, \"masked\"] = masked_str\n",
    "\n",
    "                preds = []\n",
    "                unmasked = []\n",
    "                if len(masked_str) > 512:\n",
    "                    try:\n",
    "                        unmasked = unmasker(masked_str[:512])\n",
    "                    except Exception as e:\n",
    "                        print(e)\n",
    "                        print(index)\n",
    "                else:\n",
    "                    try:\n",
    "                        unmasked = unmasker(masked_str)\n",
    "                    except Exception as e:\n",
    "                        print(e)\n",
    "                        print(index)\n",
    "\n",
    "                for i in unmasked:\n",
    "                    preds.append(i[\"token_str\"])\n",
    "\n",
    "                dataset_temp.at[index, \"preds\"] = preds\n",
    "\n",
    "                cnt = 1\n",
    "\n",
    "    dataset_temp.to_csv(\"toxigen_masked_pred_\" + group + \".csv\", index=False, quoting=csv.QUOTE_NONNUMERIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [2:21:19<00:00, 1059.90s/it]  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "directory = os.fsencode(\"masked_data\")\n",
    "\n",
    "for file in tqdm(os.listdir(directory)):\n",
    "\n",
    "    filename = os.fsdecode(file)\n",
    "    dataset_temp = pd.read_csv(\"masked_data/\" + filename)\n",
    "\n",
    "    dataset_temp[\"masked_dobj\"] = \"\"\n",
    "    dataset_temp[\"dobj\"] = \"\"\n",
    "    dataset_temp[\"preds_dobj\"] = \"\"\n",
    "\n",
    "    for index, row in dataset_temp.iterrows():\n",
    "        cnt = 0\n",
    "        # Access row values using row['column_name']\n",
    "        doc = nlp(row['generation'])\n",
    "        for t in doc:\n",
    "            if t.dep_ == \"dobj\" and cnt == 0:\n",
    "                dataset_temp.at[index, \"dobj\"] = t.text\n",
    "                masked_str = dataset_temp.at[index, \"generation\"].replace(t.text, \"<mask>\", 1)\n",
    "                dataset_temp.at[index, \"masked_dobj\"] = masked_str\n",
    "\n",
    "                preds = []\n",
    "                unmasked = []\n",
    "                if len(masked_str) > 512:\n",
    "                    try:\n",
    "                        unmasked = unmasker(masked_str[:512])\n",
    "                    except Exception as e:\n",
    "                        print(e)\n",
    "                        print(index)\n",
    "                else:\n",
    "                    try:\n",
    "                        unmasked = unmasker(masked_str)\n",
    "                    except Exception as e:\n",
    "                        print(e)\n",
    "                        print(index)\n",
    "\n",
    "                for i in unmasked:\n",
    "                    preds.append(i[\"token_str\"])\n",
    "\n",
    "                dataset_temp.at[index, \"preds_dobj\"] = preds\n",
    "\n",
    "                cnt = 1\n",
    "\n",
    "    dataset_temp.to_csv(\"masked_data/\" + filename, index=False, quoting=csv.QUOTE_NONNUMERIC)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "huggingface",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
