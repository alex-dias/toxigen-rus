{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import pipeline\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "toxigen_roberta = pipeline(\"text-classification\", model=\"tomh/toxigen_roberta\", device=device, tokenizer=\"tomh/toxigen_roberta\", max_length=512, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]c:\\Users\\Alexandre\\miniconda3\\envs\\huggingface\\lib\\site-packages\\transformers\\pipelines\\base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      " 12%|█▎        | 1/8 [05:51<40:57, 351.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxigen_masked_pred_lgbtq.csv done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alexandre\\miniconda3\\envs\\huggingface\\lib\\site-packages\\transformers\\pipelines\\base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      " 25%|██▌       | 2/8 [11:11<33:19, 333.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxigen_masked_pred_mental_dis.csv done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alexandre\\miniconda3\\envs\\huggingface\\lib\\site-packages\\transformers\\pipelines\\base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      " 38%|███▊      | 3/8 [16:43<27:43, 332.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxigen_masked_pred_mexican.csv done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alexandre\\miniconda3\\envs\\huggingface\\lib\\site-packages\\transformers\\pipelines\\base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      " 50%|█████     | 4/8 [22:19<22:14, 333.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxigen_masked_pred_middle_east.csv done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alexandre\\miniconda3\\envs\\huggingface\\lib\\site-packages\\transformers\\pipelines\\base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      " 62%|██████▎   | 5/8 [27:35<16:22, 327.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxigen_masked_pred_muslim.csv done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alexandre\\miniconda3\\envs\\huggingface\\lib\\site-packages\\transformers\\pipelines\\base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      " 75%|███████▌  | 6/8 [32:50<10:46, 323.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxigen_masked_pred_native_american.csv done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alexandre\\miniconda3\\envs\\huggingface\\lib\\site-packages\\transformers\\pipelines\\base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      " 88%|████████▊ | 7/8 [37:04<05:00, 300.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxigen_masked_pred_physical_dis.csv done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alexandre\\miniconda3\\envs\\huggingface\\lib\\site-packages\\transformers\\pipelines\\base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "100%|██████████| 8/8 [42:13<00:00, 316.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxigen_masked_pred_women.csv done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "directory = os.fsencode(\"masked_data\")\n",
    "    \n",
    "for file in tqdm(os.listdir(directory)):\n",
    "    filename = os.fsdecode(file)\n",
    "    df = pd.read_csv(\"masked_data/\" + filename)\n",
    "\n",
    "    df['masked'] = df['masked'].apply(lambda x: str(x)[:512])\n",
    "\n",
    "    df['dict'] = df['masked'].apply(lambda x: toxigen_roberta(str(x))[0])\n",
    "\n",
    "    df['pred_label_masked'] = df['dict'].apply(lambda x: int(x['label'][-1]))\n",
    "    df['pred_score_masked'] = df['dict'].apply(lambda x: x['score'])\n",
    "\n",
    "    df = df.drop(columns=['dict'])\n",
    "\n",
    "    df.to_csv(\"masked_data/\" + filename, index=False)\n",
    "\n",
    "    print(filename + \" done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/13 [00:00<?, ?it/s]c:\\Users\\Alexandre\\miniconda3\\envs\\huggingface\\lib\\site-packages\\transformers\\pipelines\\base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "  8%|▊         | 1/13 [06:42<1:20:27, 402.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxigen_masked_pred_asian.csv done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alexandre\\miniconda3\\envs\\huggingface\\lib\\site-packages\\transformers\\pipelines\\base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      " 15%|█▌        | 2/13 [13:12<1:12:27, 395.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxigen_masked_pred_black.csv done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alexandre\\miniconda3\\envs\\huggingface\\lib\\site-packages\\transformers\\pipelines\\base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      " 23%|██▎       | 3/13 [19:04<1:02:35, 375.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxigen_masked_pred_chinese.csv done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alexandre\\miniconda3\\envs\\huggingface\\lib\\site-packages\\transformers\\pipelines\\base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      " 31%|███       | 4/13 [25:03<55:19, 368.87s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxigen_masked_pred_jewish.csv done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alexandre\\miniconda3\\envs\\huggingface\\lib\\site-packages\\transformers\\pipelines\\base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      " 38%|███▊      | 5/13 [30:38<47:33, 356.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxigen_masked_pred_latino.csv done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alexandre\\miniconda3\\envs\\huggingface\\lib\\site-packages\\transformers\\pipelines\\base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      " 46%|████▌     | 6/13 [36:49<42:11, 361.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxigen_masked_pred_lgbtq.csv done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alexandre\\miniconda3\\envs\\huggingface\\lib\\site-packages\\transformers\\pipelines\\base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      " 54%|█████▍    | 7/13 [42:20<35:09, 351.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxigen_masked_pred_mental_dis.csv done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alexandre\\miniconda3\\envs\\huggingface\\lib\\site-packages\\transformers\\pipelines\\base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      " 62%|██████▏   | 8/13 [47:44<28:33, 342.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxigen_masked_pred_mexican.csv done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alexandre\\miniconda3\\envs\\huggingface\\lib\\site-packages\\transformers\\pipelines\\base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      " 69%|██████▉   | 9/13 [53:12<22:33, 338.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxigen_masked_pred_middle_east.csv done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alexandre\\miniconda3\\envs\\huggingface\\lib\\site-packages\\transformers\\pipelines\\base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      " 77%|███████▋  | 10/13 [58:57<17:00, 340.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxigen_masked_pred_muslim.csv done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alexandre\\miniconda3\\envs\\huggingface\\lib\\site-packages\\transformers\\pipelines\\base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      " 85%|████████▍ | 11/13 [1:04:31<11:16, 338.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxigen_masked_pred_native_american.csv done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alexandre\\miniconda3\\envs\\huggingface\\lib\\site-packages\\transformers\\pipelines\\base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      " 92%|█████████▏| 12/13 [1:08:58<05:16, 316.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxigen_masked_pred_physical_dis.csv done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alexandre\\miniconda3\\envs\\huggingface\\lib\\site-packages\\transformers\\pipelines\\base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "100%|██████████| 13/13 [1:14:28<00:00, 343.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxigen_masked_pred_women.csv done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "directory = os.fsencode(\"masked_data\")\n",
    "    \n",
    "for file in tqdm(os.listdir(directory)):\n",
    "    filename = os.fsdecode(file)\n",
    "    df = pd.read_csv(\"masked_data/\" + filename)\n",
    "\n",
    "    df['masked_dobj'] = df['masked_dobj'].apply(lambda x: str(x)[:512])\n",
    "\n",
    "    df['dict'] = df['masked_dobj'].apply(lambda x: toxigen_roberta(str(x))[0])\n",
    "\n",
    "    df['pred_label_masked_dobj'] = df['dict'].apply(lambda x: int(x['label'][-1]))\n",
    "    df['pred_score_masked_dobj'] = df['dict'].apply(lambda x: x['score'])\n",
    "\n",
    "    df = df.drop(columns=['dict'])\n",
    "\n",
    "    df.to_csv(\"masked_data/\" + filename, index=False)\n",
    "\n",
    "    print(filename + \" done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/13 [00:00<?, ?it/s]c:\\Users\\Alexandre\\miniconda3\\envs\\huggingface\\lib\\site-packages\\transformers\\pipelines\\base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "  8%|▊         | 1/13 [05:52<1:10:24, 352.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxigen_masked_pred_asian.csv done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alexandre\\miniconda3\\envs\\huggingface\\lib\\site-packages\\transformers\\pipelines\\base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      " 15%|█▌        | 2/13 [11:49<1:05:06, 355.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxigen_masked_pred_black.csv done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alexandre\\miniconda3\\envs\\huggingface\\lib\\site-packages\\transformers\\pipelines\\base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      " 23%|██▎       | 3/13 [17:30<58:05, 348.57s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxigen_masked_pred_chinese.csv done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alexandre\\miniconda3\\envs\\huggingface\\lib\\site-packages\\transformers\\pipelines\\base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      " 31%|███       | 4/13 [23:30<52:58, 353.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxigen_masked_pred_jewish.csv done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alexandre\\miniconda3\\envs\\huggingface\\lib\\site-packages\\transformers\\pipelines\\base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      " 38%|███▊      | 5/13 [29:01<46:00, 345.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxigen_masked_pred_latino.csv done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alexandre\\miniconda3\\envs\\huggingface\\lib\\site-packages\\transformers\\pipelines\\base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      " 46%|████▌     | 6/13 [35:05<41:01, 351.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxigen_masked_pred_lgbtq.csv done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alexandre\\miniconda3\\envs\\huggingface\\lib\\site-packages\\transformers\\pipelines\\base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      " 54%|█████▍    | 7/13 [40:25<34:07, 341.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxigen_masked_pred_mental_dis.csv done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alexandre\\miniconda3\\envs\\huggingface\\lib\\site-packages\\transformers\\pipelines\\base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      " 62%|██████▏   | 8/13 [46:32<29:08, 349.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxigen_masked_pred_mexican.csv done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alexandre\\miniconda3\\envs\\huggingface\\lib\\site-packages\\transformers\\pipelines\\base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      " 69%|██████▉   | 9/13 [52:19<23:14, 348.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxigen_masked_pred_middle_east.csv done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alexandre\\miniconda3\\envs\\huggingface\\lib\\site-packages\\transformers\\pipelines\\base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      " 77%|███████▋  | 10/13 [58:01<17:19, 346.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxigen_masked_pred_muslim.csv done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alexandre\\miniconda3\\envs\\huggingface\\lib\\site-packages\\transformers\\pipelines\\base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      " 85%|████████▍ | 11/13 [1:03:35<11:25, 342.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxigen_masked_pred_native_american.csv done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alexandre\\miniconda3\\envs\\huggingface\\lib\\site-packages\\transformers\\pipelines\\base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      " 92%|█████████▏| 12/13 [1:08:01<05:19, 319.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxigen_masked_pred_physical_dis.csv done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alexandre\\miniconda3\\envs\\huggingface\\lib\\site-packages\\transformers\\pipelines\\base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "100%|██████████| 13/13 [1:13:27<00:00, 339.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxigen_masked_pred_women.csv done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "directory = os.fsencode(\"masked_data\")\n",
    "    \n",
    "for file in tqdm(os.listdir(directory)):\n",
    "    filename = os.fsdecode(file)\n",
    "    df = pd.read_csv(\"masked_data/\" + filename)\n",
    "\n",
    "    df['generation'] = df['generation'].apply(lambda x: str(x)[:500])\n",
    "\n",
    "    df['dict'] = df['generation'].apply(lambda x: toxigen_roberta(str(x))[0])\n",
    "\n",
    "    df['pred_label_notmasked'] = df['dict'].apply(lambda x: int(x['label'][-1]))\n",
    "    df['pred_score_notmasked'] = df['dict'].apply(lambda x: x['score'])\n",
    "\n",
    "    df = df.drop(columns=['dict'])\n",
    "\n",
    "    df.to_csv(\"masked_data/\" + filename, index=False)\n",
    "\n",
    "    print(filename + \" done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"completeDataset_inference.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Tweet Treated</th>\n",
       "      <th>Tweet Raw</th>\n",
       "      <th>Url</th>\n",
       "      <th>Id</th>\n",
       "      <th>index</th>\n",
       "      <th>model_inference</th>\n",
       "      <th>normal_score</th>\n",
       "      <th>hate_speech_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-01 23:59:41+00:00</td>\n",
       "      <td>goldfinger &amp;amp; from russia with love</td>\n",
       "      <td>@donwinslow Goldfinger &amp;amp; From Russia with ...</td>\n",
       "      <td>https://twitter.com/coolvee2222/status/1477429...</td>\n",
       "      <td>1477429351952130051</td>\n",
       "      <td>0</td>\n",
       "      <td>nothate</td>\n",
       "      <td>0.9996</td>\n",
       "      <td>0.0004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-01-01 23:59:23+00:00</td>\n",
       "      <td>thank you! russia musume 1 or dream note please!</td>\n",
       "      <td>@aiuncensored thank you! russia musume 1 or dr...</td>\n",
       "      <td>https://twitter.com/CsarVsq30904305/status/147...</td>\n",
       "      <td>1477429275926179841</td>\n",
       "      <td>1</td>\n",
       "      <td>nothate</td>\n",
       "      <td>0.9997</td>\n",
       "      <td>0.0003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-01 23:59:23+00:00</td>\n",
       "      <td>new in shop! vintage russian nesting dolls, cl...</td>\n",
       "      <td>New in Shop! Vintage Russian Nesting Dolls, Cl...</td>\n",
       "      <td>https://twitter.com/trashtique/status/14774292...</td>\n",
       "      <td>1477429275024310273</td>\n",
       "      <td>2</td>\n",
       "      <td>nothate</td>\n",
       "      <td>0.9997</td>\n",
       "      <td>0.0003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-01-01 23:59:13+00:00</td>\n",
       "      <td>if the chinese government donated to the gqp ...</td>\n",
       "      <td>@RepThomasMassie If the Chinese government don...</td>\n",
       "      <td>https://twitter.com/SouthernNotSt/status/14774...</td>\n",
       "      <td>1477429235589566466</td>\n",
       "      <td>3</td>\n",
       "      <td>nothate</td>\n",
       "      <td>0.9987</td>\n",
       "      <td>0.0013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-01-01 23:58:55+00:00</td>\n",
       "      <td>i'm dying to know how redacted tonight fits i...</td>\n",
       "      <td>@jimstewartson I'm dying to know how Redacted ...</td>\n",
       "      <td>https://twitter.com/rscobe1920/status/14774291...</td>\n",
       "      <td>1477429159307661317</td>\n",
       "      <td>4</td>\n",
       "      <td>nothate</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Date  \\\n",
       "0  2022-01-01 23:59:41+00:00   \n",
       "1  2022-01-01 23:59:23+00:00   \n",
       "2  2022-01-01 23:59:23+00:00   \n",
       "3  2022-01-01 23:59:13+00:00   \n",
       "4  2022-01-01 23:58:55+00:00   \n",
       "\n",
       "                                       Tweet Treated  \\\n",
       "0             goldfinger &amp; from russia with love   \n",
       "1   thank you! russia musume 1 or dream note please!   \n",
       "2  new in shop! vintage russian nesting dolls, cl...   \n",
       "3   if the chinese government donated to the gqp ...   \n",
       "4   i'm dying to know how redacted tonight fits i...   \n",
       "\n",
       "                                           Tweet Raw  \\\n",
       "0  @donwinslow Goldfinger &amp; From Russia with ...   \n",
       "1  @aiuncensored thank you! russia musume 1 or dr...   \n",
       "2  New in Shop! Vintage Russian Nesting Dolls, Cl...   \n",
       "3  @RepThomasMassie If the Chinese government don...   \n",
       "4  @jimstewartson I'm dying to know how Redacted ...   \n",
       "\n",
       "                                                 Url                   Id  \\\n",
       "0  https://twitter.com/coolvee2222/status/1477429...  1477429351952130051   \n",
       "1  https://twitter.com/CsarVsq30904305/status/147...  1477429275926179841   \n",
       "2  https://twitter.com/trashtique/status/14774292...  1477429275024310273   \n",
       "3  https://twitter.com/SouthernNotSt/status/14774...  1477429235589566466   \n",
       "4  https://twitter.com/rscobe1920/status/14774291...  1477429159307661317   \n",
       "\n",
       "   index model_inference  normal_score  hate_speech_score  \n",
       "0      0         nothate        0.9996             0.0004  \n",
       "1      1         nothate        0.9997             0.0003  \n",
       "2      2         nothate        0.9997             0.0003  \n",
       "3      3         nothate        0.9987             0.0013  \n",
       "4      4         nothate        0.9999             0.0001  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alexandre\\miniconda3\\envs\\huggingface\\lib\\site-packages\\transformers\\pipelines\\base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "df['Tweet Treated'] = df['Tweet Treated'].apply(lambda x: str(x)[:512])\n",
    "\n",
    "df['dict'] = df['Tweet Treated'].apply(lambda x: toxigen_roberta(str(x))[0])\n",
    "\n",
    "df['pred_label_notmasked'] = df['dict'].apply(lambda x: int(x['label'][-1]))\n",
    "df['pred_score_notmasked'] = df['dict'].apply(lambda x: x['score'])\n",
    "\n",
    "df = df.drop(columns=['dict'])\n",
    "\n",
    "df.to_csv(\"masked_data/\" + \"completeDataset_inference_roberta.csv\", index=False, quoting=csv.QUOTE_NONNUMERIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Tweet Treated</th>\n",
       "      <th>Tweet Raw</th>\n",
       "      <th>Url</th>\n",
       "      <th>Id</th>\n",
       "      <th>index</th>\n",
       "      <th>model_inference</th>\n",
       "      <th>normal_score</th>\n",
       "      <th>hate_speech_score</th>\n",
       "      <th>pred_label_notmasked</th>\n",
       "      <th>pred_score_notmasked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-01 23:59:41+00:00</td>\n",
       "      <td>goldfinger &amp;amp; from russia with love</td>\n",
       "      <td>@donwinslow Goldfinger &amp;amp; From Russia with ...</td>\n",
       "      <td>https://twitter.com/coolvee2222/status/1477429...</td>\n",
       "      <td>1477429351952130051</td>\n",
       "      <td>0</td>\n",
       "      <td>nothate</td>\n",
       "      <td>0.9996</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-01-01 23:59:23+00:00</td>\n",
       "      <td>thank you! russia musume 1 or dream note please!</td>\n",
       "      <td>@aiuncensored thank you! russia musume 1 or dr...</td>\n",
       "      <td>https://twitter.com/CsarVsq30904305/status/147...</td>\n",
       "      <td>1477429275926179841</td>\n",
       "      <td>1</td>\n",
       "      <td>nothate</td>\n",
       "      <td>0.9997</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-01 23:59:23+00:00</td>\n",
       "      <td>new in shop! vintage russian nesting dolls, cl...</td>\n",
       "      <td>New in Shop! Vintage Russian Nesting Dolls, Cl...</td>\n",
       "      <td>https://twitter.com/trashtique/status/14774292...</td>\n",
       "      <td>1477429275024310273</td>\n",
       "      <td>2</td>\n",
       "      <td>nothate</td>\n",
       "      <td>0.9997</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-01-01 23:59:13+00:00</td>\n",
       "      <td>if the chinese government donated to the gqp ...</td>\n",
       "      <td>@RepThomasMassie If the Chinese government don...</td>\n",
       "      <td>https://twitter.com/SouthernNotSt/status/14774...</td>\n",
       "      <td>1477429235589566466</td>\n",
       "      <td>3</td>\n",
       "      <td>nothate</td>\n",
       "      <td>0.9987</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0</td>\n",
       "      <td>0.924367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-01-01 23:58:55+00:00</td>\n",
       "      <td>i'm dying to know how redacted tonight fits i...</td>\n",
       "      <td>@jimstewartson I'm dying to know how Redacted ...</td>\n",
       "      <td>https://twitter.com/rscobe1920/status/14774291...</td>\n",
       "      <td>1477429159307661317</td>\n",
       "      <td>4</td>\n",
       "      <td>nothate</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999380</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Date  \\\n",
       "0  2022-01-01 23:59:41+00:00   \n",
       "1  2022-01-01 23:59:23+00:00   \n",
       "2  2022-01-01 23:59:23+00:00   \n",
       "3  2022-01-01 23:59:13+00:00   \n",
       "4  2022-01-01 23:58:55+00:00   \n",
       "\n",
       "                                       Tweet Treated  \\\n",
       "0             goldfinger &amp; from russia with love   \n",
       "1   thank you! russia musume 1 or dream note please!   \n",
       "2  new in shop! vintage russian nesting dolls, cl...   \n",
       "3   if the chinese government donated to the gqp ...   \n",
       "4   i'm dying to know how redacted tonight fits i...   \n",
       "\n",
       "                                           Tweet Raw  \\\n",
       "0  @donwinslow Goldfinger &amp; From Russia with ...   \n",
       "1  @aiuncensored thank you! russia musume 1 or dr...   \n",
       "2  New in Shop! Vintage Russian Nesting Dolls, Cl...   \n",
       "3  @RepThomasMassie If the Chinese government don...   \n",
       "4  @jimstewartson I'm dying to know how Redacted ...   \n",
       "\n",
       "                                                 Url                   Id  \\\n",
       "0  https://twitter.com/coolvee2222/status/1477429...  1477429351952130051   \n",
       "1  https://twitter.com/CsarVsq30904305/status/147...  1477429275926179841   \n",
       "2  https://twitter.com/trashtique/status/14774292...  1477429275024310273   \n",
       "3  https://twitter.com/SouthernNotSt/status/14774...  1477429235589566466   \n",
       "4  https://twitter.com/rscobe1920/status/14774291...  1477429159307661317   \n",
       "\n",
       "   index model_inference  normal_score  hate_speech_score  \\\n",
       "0      0         nothate        0.9996             0.0004   \n",
       "1      1         nothate        0.9997             0.0003   \n",
       "2      2         nothate        0.9997             0.0003   \n",
       "3      3         nothate        0.9987             0.0013   \n",
       "4      4         nothate        0.9999             0.0001   \n",
       "\n",
       "   pred_label_notmasked  pred_score_notmasked  \n",
       "0                     0              0.999273  \n",
       "1                     0              0.999333  \n",
       "2                     0              0.999286  \n",
       "3                     0              0.924367  \n",
       "4                     0              0.999380  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pred_label_notmasked\n",
       "0    818308\n",
       "1    202913\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.pred_label_notmasked.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model_inference\n",
       "nothate    963026\n",
       "hate        58195\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.model_inference.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model_inference  pred_label_notmasked\n",
       "hate             1                        45355\n",
       "                 0                        12840\n",
       "nothate          0                       805468\n",
       "                 1                       157558\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('model_inference')['pred_label_notmasked'].value_counts(sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alexandre\\miniconda3\\envs\\huggingface\\lib\\site-packages\\transformers\\pipelines\\base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "c:\\Users\\Alexandre\\miniconda3\\envs\\huggingface\\lib\\site-packages\\transformers\\pipelines\\base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"masked_data/\" + \"toxigen_masked_pred_russian.csv\")\n",
    "\n",
    "df['masked_dobj'] = df['masked_dobj'].apply(lambda x: str(x)[:512])\n",
    "\n",
    "df['dict'] = df['masked_dobj'].apply(lambda x: toxigen_roberta(str(x))[0])\n",
    "\n",
    "df['pred_label_masked_dobj'] = df['dict'].apply(lambda x: int(x['label'][-1]))\n",
    "df['pred_score_masked_dobj'] = df['dict'].apply(lambda x: x['score'])\n",
    "\n",
    "df = df.drop(columns=['dict'])\n",
    "\n",
    "df['masked'] = df['masked'].apply(lambda x: str(x)[:512])\n",
    "\n",
    "df['dict'] = df['masked'].apply(lambda x: toxigen_roberta(str(x))[0])\n",
    "\n",
    "df['pred_label_masked'] = df['dict'].apply(lambda x: int(x['label'][-1]))\n",
    "df['pred_score_masked'] = df['dict'].apply(lambda x: x['score'])\n",
    "\n",
    "df = df.drop(columns=['dict'])\n",
    "\n",
    "df.to_csv(\"masked_data/toxigen_masked_pred_\" + \"russian\" + \".csv\", index=False, quoting=csv.QUOTE_NONNUMERIC)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "huggingface",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
