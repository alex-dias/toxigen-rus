{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_stats(group, type = \"simple\"):\n",
    "    df = pd.read_csv(\"masked_data/toxigen_masked_pred_\" + group + \".csv\")\n",
    "\n",
    "    df['eval_shift'] = df['prompt_label'] - df['pred_label_masked']\n",
    "\n",
    "    counts = df.eval_shift.value_counts()\n",
    "    percs = df.eval_shift.value_counts(normalize=True)\n",
    "    values = pd.concat([counts,percs], axis=1, keys=['count', 'percentage'])\n",
    "\n",
    "    df['pred_score_masked'] = (df.pred_score_masked - .5)/.5\n",
    "\n",
    "    df_equal = df[df.eval_shift == 0]\n",
    "    df_asc = df[df.eval_shift == -1]\n",
    "    df_desc = df[df.eval_shift == 1]\n",
    "\n",
    "    print(\"------------- Group: \" + group + \" -------------\")\n",
    "    print(\"Total: \" + str(len(df)))\n",
    "    print(values)\n",
    "    print(\"\")\n",
    "\n",
    "    if type == \"full\":\n",
    "\n",
    "        print(\"Equal:\")\n",
    "        print(df_equal[['roberta_prediction','pred_score_masked']].describe())\n",
    "        print(\"\")\n",
    "\n",
    "        print(\"Desc:\")\n",
    "        print(df_desc[['roberta_prediction','pred_score_masked']].describe())\n",
    "        print(\"\")\n",
    "\n",
    "        print(\"Asc:\")\n",
    "        print(df_asc[['roberta_prediction','pred_score_masked']].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_stats_notmasked(group, type = \"simple\"):\n",
    "    df = pd.read_csv(\"masked_data/toxigen_masked_pred_\" + group + \".csv\")\n",
    "\n",
    "    df['eval_shift'] = df['prompt_label'] - df['pred_label_notmasked']\n",
    "\n",
    "    counts = df.eval_shift.value_counts()\n",
    "    percs = df.eval_shift.value_counts(normalize=True)\n",
    "    values = pd.concat([counts,percs], axis=1, keys=['count', 'percentage'])\n",
    "\n",
    "    #df['pred_score_masked'] = (df.pred_score_masked - .5)/.5\n",
    "\n",
    "    df_equal = df[df.eval_shift == 0]\n",
    "    df_asc = df[df.eval_shift == -1]\n",
    "    df_desc = df[df.eval_shift == 1]\n",
    "\n",
    "    print(\"------------- Group: \" + group + \" -------------\")\n",
    "    print(\"Total: \" + str(len(df)))\n",
    "    print(values)\n",
    "    print(\"\")\n",
    "\n",
    "    if type == \"full\":\n",
    "\n",
    "        print(\"Equal:\")\n",
    "        print(df_equal[['roberta_prediction','pred_score_notmasked']].describe())\n",
    "        print(\"\")\n",
    "\n",
    "        print(\"Desc:\")\n",
    "        print(df_desc[['roberta_prediction','pred_score_notmasked']].describe())\n",
    "        print(\"\")\n",
    "\n",
    "        print(\"Asc:\")\n",
    "        print(df_asc[['roberta_prediction','pred_score_notmasked']].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_stats_dobj(group, type = \"simple\"):\n",
    "    df = pd.read_csv(\"masked_data/toxigen_masked_pred_\" + group + \".csv\")\n",
    "\n",
    "    df['eval_shift'] = df['prompt_label'] - df['pred_label_masked_dobj']\n",
    "\n",
    "    counts = df.eval_shift.value_counts()\n",
    "    percs = df.eval_shift.value_counts(normalize=True)\n",
    "    values = pd.concat([counts,percs], axis=1, keys=['count', 'percentage'])\n",
    "\n",
    "    #df['pred_score_masked_dobj'] = (df.pred_score_masked - .5)/.5\n",
    "\n",
    "    df_equal = df[df.eval_shift == 0]\n",
    "    df_asc = df[df.eval_shift == -1]\n",
    "    df_desc = df[df.eval_shift == 1]\n",
    "\n",
    "    print(\"------------- Group: \" + group + \" -------------\")\n",
    "    print(\"Total: \" + str(len(df)))\n",
    "    print(values)\n",
    "    print(\"\")\n",
    "\n",
    "    if type == \"full\":\n",
    "\n",
    "        print(\"Equal:\")\n",
    "        print(df_equal[['roberta_prediction','pred_score_masked_dobj']].describe())\n",
    "        print(\"\")\n",
    "\n",
    "        print(\"Desc:\")\n",
    "        print(df_desc[['roberta_prediction','pred_score_masked_dobj']].describe())\n",
    "        print(\"\")\n",
    "\n",
    "        print(\"Asc:\")\n",
    "        print(df_asc[['roberta_prediction','pred_score_masked_dobj']].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_stats_russ(group, type = \"simple\"):\n",
    "    df = pd.read_csv(\"masked_data/toxigen_masked_pred_\" + group + \".csv\")\n",
    "\n",
    "    df['eval_shift'] = df['pred_label_notmasked'] - df['pred_label_masked']\n",
    "\n",
    "    counts = df.eval_shift.value_counts()\n",
    "    percs = df.eval_shift.value_counts(normalize=True)\n",
    "    values = pd.concat([counts,percs], axis=1, keys=['count', 'percentage'])\n",
    "\n",
    "    df['pred_score_masked'] = (df.pred_score_masked - .5)/.5\n",
    "\n",
    "    df_equal = df[df.eval_shift == 0]\n",
    "    df_asc = df[df.eval_shift == -1]\n",
    "    df_desc = df[df.eval_shift == 1]\n",
    "\n",
    "    print(\"------------- Group: \" + group + \" -------------\")\n",
    "    print(\"Total: \" + str(len(df)))\n",
    "    print(values)\n",
    "    print(\"\")\n",
    "\n",
    "    if type == \"full\":\n",
    "\n",
    "        print(\"Equal:\")\n",
    "        print(df_equal[['pred_score_notmasked','pred_score_masked']].describe())\n",
    "        print(\"\")\n",
    "\n",
    "        print(\"Desc:\")\n",
    "        print(df_desc[['pred_score_notmasked','pred_score_masked']].describe())\n",
    "        print(\"\")\n",
    "\n",
    "        print(\"Asc:\")\n",
    "        print(df_asc[['pred_score_notmasked','pred_score_masked']].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------- Group: black -------------\n",
      "Total: 19878\n",
      "            count  percentage\n",
      "eval_shift                   \n",
      " 0          14687    0.738857\n",
      " 1           4803    0.241624\n",
      "-1            388    0.019519\n",
      "\n",
      "\n",
      "------------- Group: asian -------------\n",
      "Total: 19884\n",
      "            count  percentage\n",
      "eval_shift                   \n",
      " 0          14218    0.715047\n",
      " 1           5463    0.274744\n",
      "-1            203    0.010209\n",
      "\n",
      "\n",
      "------------- Group: native_american -------------\n",
      "Total: 19360\n",
      "            count  percentage\n",
      "eval_shift                   \n",
      " 0          13162    0.679855\n",
      " 1           5995    0.309659\n",
      "-1            203    0.010486\n",
      "\n",
      "\n",
      "------------- Group: muslim -------------\n",
      "Total: 19855\n",
      "            count  percentage\n",
      "eval_shift                   \n",
      " 0          14055    0.707882\n",
      " 1           5396    0.271770\n",
      "-1            404    0.020348\n",
      "\n",
      "\n",
      "------------- Group: latino -------------\n",
      "Total: 18545\n",
      "            count  percentage\n",
      "eval_shift                   \n",
      " 0          12426    0.670046\n",
      " 1           5259    0.283580\n",
      "-1            860    0.046374\n",
      "\n",
      "\n",
      "------------- Group: jewish -------------\n",
      "Total: 19542\n",
      "            count  percentage\n",
      "eval_shift                   \n",
      " 0          14313    0.732422\n",
      " 1           4644    0.237642\n",
      "-1            585    0.029936\n",
      "\n",
      "\n",
      "------------- Group: chinese -------------\n",
      "Total: 19059\n",
      "            count  percentage\n",
      "eval_shift                   \n",
      " 0          12668    0.664673\n",
      " 1           5823    0.305525\n",
      "-1            568    0.029802\n",
      "\n",
      "\n",
      "------------- Group: lgbtq -------------\n",
      "Total: 20945\n",
      "            count  percentage\n",
      "eval_shift                   \n",
      " 0          14471    0.690905\n",
      " 1           6151    0.293674\n",
      "-1            323    0.015421\n",
      "\n",
      "\n",
      "------------- Group: mental_dis -------------\n",
      "Total: 18659\n",
      "            count  percentage\n",
      "eval_shift                   \n",
      " 0          12085    0.647677\n",
      " 1           6429    0.344552\n",
      "-1            145    0.007771\n",
      "\n",
      "\n",
      "------------- Group: physical_dis -------------\n",
      "Total: 15499\n",
      "            count  percentage\n",
      "eval_shift                   \n",
      " 0          10047    0.648235\n",
      " 1           5261    0.339441\n",
      "-1            191    0.012323\n",
      "\n",
      "\n",
      "------------- Group: mexican -------------\n",
      "Total: 20353\n",
      "            count  percentage\n",
      "eval_shift                   \n",
      " 0          14904    0.732275\n",
      " 1           5019    0.246598\n",
      "-1            430    0.021127\n",
      "\n",
      "\n",
      "------------- Group: women -------------\n",
      "Total: 19075\n",
      "            count  percentage\n",
      "eval_shift                   \n",
      " 0          13076    0.685505\n",
      " 1           5724    0.300079\n",
      "-1            275    0.014417\n",
      "\n",
      "\n",
      "------------- Group: middle_east -------------\n",
      "Total: 20297\n",
      "            count  percentage\n",
      "eval_shift                   \n",
      " 0          15088    0.743361\n",
      " 1           4888    0.240824\n",
      "-1            321    0.015815\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for group in ['black', 'asian', 'native_american', 'muslim', 'latino', 'jewish',\n",
    "       'chinese', 'lgbtq', 'mental_dis', 'physical_dis', 'mexican',\n",
    "       'women', 'middle_east']:\n",
    "    \n",
    "    extract_stats(group)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------- Group: black -------------\n",
      "Total: 19878\n",
      "            count  percentage\n",
      "eval_shift                   \n",
      " 0          14687    0.738857\n",
      " 1           4803    0.241624\n",
      "-1            388    0.019519\n",
      "\n",
      "Equal:\n",
      "       roberta_prediction  pred_score_masked\n",
      "count        14687.000000       14687.000000\n",
      "mean             0.257260           0.923129\n",
      "std              0.394939           0.170122\n",
      "min              0.001000           0.000040\n",
      "25%              0.001000           0.955900\n",
      "50%              0.005000           0.989483\n",
      "75%              0.582000           0.996720\n",
      "max              0.993000           0.998896\n",
      "\n",
      "Desc:\n",
      "       roberta_prediction  pred_score_masked\n",
      "count         4803.000000        4803.000000\n",
      "mean             0.260633           0.879741\n",
      "std              0.395699           0.228672\n",
      "min              0.001000           0.000914\n",
      "25%              0.001000           0.897062\n",
      "50%              0.005000           0.990521\n",
      "75%              0.621500           0.996550\n",
      "max              0.993000           0.998851\n",
      "\n",
      "Asc:\n",
      "       roberta_prediction  pred_score_masked\n",
      "count          388.000000         388.000000\n",
      "mean             0.244361           0.593573\n",
      "std              0.391496           0.300281\n",
      "min              0.001000           0.001069\n",
      "25%              0.001000           0.335571\n",
      "50%              0.003000           0.673974\n",
      "75%              0.477250           0.854422\n",
      "max              0.992000           0.982530\n",
      "\n",
      "------------- Group: asian -------------\n",
      "Total: 19884\n",
      "            count  percentage\n",
      "eval_shift                   \n",
      " 0          14218    0.715047\n",
      " 1           5463    0.274744\n",
      "-1            203    0.010209\n",
      "\n",
      "Equal:\n",
      "       roberta_prediction  pred_score_masked\n",
      "count        14218.000000       14218.000000\n",
      "mean             0.264749           0.935271\n",
      "std              0.399749           0.159065\n",
      "min              0.001000           0.000051\n",
      "25%              0.001000           0.969161\n",
      "50%              0.005000           0.995722\n",
      "75%              0.666000           0.997855\n",
      "max              0.993000           0.998893\n",
      "\n",
      "Desc:\n",
      "       roberta_prediction  pred_score_masked\n",
      "count         5463.000000        5463.000000\n",
      "mean             0.262363           0.887519\n",
      "std              0.397622           0.221601\n",
      "min              0.001000           0.001028\n",
      "25%              0.001000           0.911323\n",
      "50%              0.006000           0.991047\n",
      "75%              0.616500           0.996550\n",
      "max              0.993000           0.998843\n",
      "\n",
      "Asc:\n",
      "       roberta_prediction  pred_score_masked\n",
      "count          203.000000         203.000000\n",
      "mean             0.299847           0.633374\n",
      "std              0.413269           0.291115\n",
      "min              0.001000           0.005013\n",
      "25%              0.001000           0.423986\n",
      "50%              0.005000           0.724573\n",
      "75%              0.797500           0.872464\n",
      "max              0.993000           0.982277\n",
      "\n",
      "------------- Group: native_american -------------\n",
      "Total: 19360\n",
      "            count  percentage\n",
      "eval_shift                   \n",
      " 0          13162    0.679855\n",
      " 1           5995    0.309659\n",
      "-1            203    0.010486\n",
      "\n",
      "Equal:\n",
      "       roberta_prediction  pred_score_masked\n",
      "count        13162.000000       13162.000000\n",
      "mean             0.260475           0.936089\n",
      "std              0.396813           0.160090\n",
      "min              0.001000           0.000679\n",
      "25%              0.001000           0.973058\n",
      "50%              0.005000           0.996541\n",
      "75%              0.625000           0.997942\n",
      "max              0.993000           0.998874\n",
      "\n",
      "Desc:\n",
      "       roberta_prediction  pred_score_masked\n",
      "count         5995.000000        5995.000000\n",
      "mean             0.265505           0.912536\n",
      "std              0.398185           0.193590\n",
      "min              0.001000           0.000747\n",
      "25%              0.001000           0.952500\n",
      "50%              0.005000           0.994338\n",
      "75%              0.669500           0.996550\n",
      "max              0.993000           0.998885\n",
      "\n",
      "Asc:\n",
      "       roberta_prediction  pred_score_masked\n",
      "count          203.000000         203.000000\n",
      "mean             0.310685           0.649809\n",
      "std              0.417277           0.275941\n",
      "min              0.001000           0.015197\n",
      "25%              0.001000           0.485727\n",
      "50%              0.008000           0.701436\n",
      "75%              0.844500           0.893288\n",
      "max              0.993000           0.982840\n",
      "\n",
      "------------- Group: muslim -------------\n",
      "Total: 19855\n",
      "            count  percentage\n",
      "eval_shift                   \n",
      " 0          14055    0.707882\n",
      " 1           5396    0.271770\n",
      "-1            404    0.020348\n",
      "\n",
      "Equal:\n",
      "       roberta_prediction  pred_score_masked\n",
      "count        14055.000000       14055.000000\n",
      "mean             0.264269           0.919919\n",
      "std              0.398020           0.177922\n",
      "min              0.001000           0.001895\n",
      "25%              0.001000           0.958300\n",
      "50%              0.005000           0.992932\n",
      "75%              0.653500           0.997721\n",
      "max              0.993000           0.998883\n",
      "\n",
      "Desc:\n",
      "       roberta_prediction  pred_score_masked\n",
      "count         5396.000000        5396.000000\n",
      "mean             0.269395           0.890903\n",
      "std              0.404548           0.214147\n",
      "min              0.001000           0.002576\n",
      "25%              0.001000           0.913446\n",
      "50%              0.005000           0.990872\n",
      "75%              0.723250           0.996550\n",
      "max              0.993000           0.998874\n",
      "\n",
      "Asc:\n",
      "       roberta_prediction  pred_score_masked\n",
      "count          404.000000         404.000000\n",
      "mean             0.261433           0.628792\n",
      "std              0.405310           0.271012\n",
      "min              0.001000           0.002031\n",
      "25%              0.001000           0.445764\n",
      "50%              0.004000           0.673827\n",
      "75%              0.713250           0.878065\n",
      "max              0.993000           0.982290\n",
      "\n",
      "------------- Group: latino -------------\n",
      "Total: 18545\n",
      "            count  percentage\n",
      "eval_shift                   \n",
      " 0          12426    0.670046\n",
      " 1           5259    0.283580\n",
      "-1            860    0.046374\n",
      "\n",
      "Equal:\n",
      "       roberta_prediction  pred_score_masked\n",
      "count        12426.000000       12426.000000\n",
      "mean             0.259505           0.903391\n",
      "std              0.395380           0.190668\n",
      "min              0.001000           0.000349\n",
      "25%              0.001000           0.927703\n",
      "50%              0.005000           0.983413\n",
      "75%              0.616000           0.996550\n",
      "max              0.993000           0.998880\n",
      "\n",
      "Desc:\n",
      "       roberta_prediction  pred_score_masked\n",
      "count         5259.000000        5259.000000\n",
      "mean             0.264376           0.881615\n",
      "std              0.398576           0.227500\n",
      "min              0.001000           0.000360\n",
      "25%              0.001000           0.906797\n",
      "50%              0.006000           0.990453\n",
      "75%              0.659000           0.996550\n",
      "max              0.993000           0.998868\n",
      "\n",
      "Asc:\n",
      "       roberta_prediction  pred_score_masked\n",
      "count          860.000000         860.000000\n",
      "mean             0.260607           0.694793\n",
      "std              0.397117           0.277600\n",
      "min              0.001000           0.003805\n",
      "25%              0.001000           0.521401\n",
      "50%              0.005000           0.778716\n",
      "75%              0.622250           0.940386\n",
      "max              0.993000           0.985020\n",
      "\n",
      "------------- Group: jewish -------------\n",
      "Total: 19542\n",
      "            count  percentage\n",
      "eval_shift                   \n",
      " 0          14313    0.732422\n",
      " 1           4644    0.237642\n",
      "-1            585    0.029936\n",
      "\n",
      "Equal:\n",
      "       roberta_prediction  pred_score_masked\n",
      "count        14313.000000       14313.000000\n",
      "mean             0.261526           0.912398\n",
      "std              0.397617           0.181191\n",
      "min              0.001000           0.000186\n",
      "25%              0.001000           0.939016\n",
      "50%              0.005000           0.991215\n",
      "75%              0.642000           0.997642\n",
      "max              0.993000           0.998885\n",
      "\n",
      "Desc:\n",
      "       roberta_prediction  pred_score_masked\n",
      "count         4644.000000        4644.000000\n",
      "mean             0.263348           0.875969\n",
      "std              0.396094           0.229052\n",
      "min              0.001000           0.000756\n",
      "25%              0.001000           0.885451\n",
      "50%              0.006000           0.988083\n",
      "75%              0.639000           0.996550\n",
      "max              0.993000           0.998878\n",
      "\n",
      "Asc:\n",
      "       roberta_prediction  pred_score_masked\n",
      "count          585.000000         585.000000\n",
      "mean             0.256072           0.653427\n",
      "std              0.396583           0.296197\n",
      "min              0.001000           0.003302\n",
      "25%              0.001000           0.422776\n",
      "50%              0.004000           0.740810\n",
      "75%              0.586000           0.920549\n",
      "max              0.993000           0.982892\n",
      "\n",
      "------------- Group: chinese -------------\n",
      "Total: 19059\n",
      "            count  percentage\n",
      "eval_shift                   \n",
      " 0          12668    0.664673\n",
      " 1           5823    0.305525\n",
      "-1            568    0.029802\n",
      "\n",
      "Equal:\n",
      "       roberta_prediction  pred_score_masked\n",
      "count        12668.000000       12668.000000\n",
      "mean             0.265854           0.921367\n",
      "std              0.398964           0.177104\n",
      "min              0.001000           0.000972\n",
      "25%              0.001000           0.961716\n",
      "50%              0.005000           0.993842\n",
      "75%              0.655250           0.997896\n",
      "max              0.993000           0.998875\n",
      "\n",
      "Desc:\n",
      "       roberta_prediction  pred_score_masked\n",
      "count         5823.000000        5823.000000\n",
      "mean             0.261367           0.896477\n",
      "std              0.397968           0.204672\n",
      "min              0.001000           0.001095\n",
      "25%              0.001000           0.920469\n",
      "50%              0.005000           0.990501\n",
      "75%              0.629000           0.996550\n",
      "max              0.993000           0.998855\n",
      "\n",
      "Asc:\n",
      "       roberta_prediction  pred_score_masked\n",
      "count          568.000000         568.000000\n",
      "mean             0.264326           0.738657\n",
      "std              0.394444           0.270565\n",
      "min              0.001000           0.006469\n",
      "25%              0.001000           0.584076\n",
      "50%              0.006500           0.847865\n",
      "75%              0.629750           0.959106\n",
      "max              0.993000           0.982692\n",
      "\n",
      "------------- Group: lgbtq -------------\n",
      "Total: 20945\n",
      "            count  percentage\n",
      "eval_shift                   \n",
      " 0          14471    0.690905\n",
      " 1           6151    0.293674\n",
      "-1            323    0.015421\n",
      "\n",
      "Equal:\n",
      "       roberta_prediction  pred_score_masked\n",
      "count        14471.000000       14471.000000\n",
      "mean             0.262627           0.928396\n",
      "std              0.397989           0.172552\n",
      "min              0.001000           0.000334\n",
      "25%              0.001000           0.968919\n",
      "50%              0.005000           0.996286\n",
      "75%              0.659000           0.998084\n",
      "max              0.993000           0.998877\n",
      "\n",
      "Desc:\n",
      "       roberta_prediction  pred_score_masked\n",
      "count         6151.000000        6151.000000\n",
      "mean             0.262736           0.879921\n",
      "std              0.396342           0.225502\n",
      "min              0.001000           0.000925\n",
      "25%              0.001000           0.901747\n",
      "50%              0.006000           0.987157\n",
      "75%              0.625500           0.996550\n",
      "max              0.993000           0.998845\n",
      "\n",
      "Asc:\n",
      "       roberta_prediction  pred_score_masked\n",
      "count          323.000000         323.000000\n",
      "mean             0.310272           0.677283\n",
      "std              0.420527           0.292134\n",
      "min              0.001000           0.002689\n",
      "25%              0.001000           0.486346\n",
      "50%              0.012000           0.771307\n",
      "75%              0.873500           0.937343\n",
      "max              0.993000           0.984173\n",
      "\n",
      "------------- Group: mental_dis -------------\n",
      "Total: 18659\n",
      "            count  percentage\n",
      "eval_shift                   \n",
      " 0          12085    0.647677\n",
      " 1           6429    0.344552\n",
      "-1            145    0.007771\n",
      "\n",
      "Equal:\n",
      "       roberta_prediction  pred_score_masked\n",
      "count        12085.000000       12085.000000\n",
      "mean             0.260700           0.948749\n",
      "std              0.397204           0.142348\n",
      "min              0.001000           0.002765\n",
      "25%              0.001000           0.980479\n",
      "50%              0.005000           0.996550\n",
      "75%              0.611000           0.998235\n",
      "max              0.993000           0.998881\n",
      "\n",
      "Desc:\n",
      "       roberta_prediction  pred_score_masked\n",
      "count         6429.000000        6429.000000\n",
      "mean             0.256886           0.938620\n",
      "std              0.395163           0.165301\n",
      "min              0.001000           0.000440\n",
      "25%              0.001000           0.980651\n",
      "50%              0.005000           0.996550\n",
      "75%              0.609000           0.996550\n",
      "max              0.993000           0.998862\n",
      "\n",
      "Asc:\n",
      "       roberta_prediction  pred_score_masked\n",
      "count          145.000000         145.000000\n",
      "mean             0.364710           0.659916\n",
      "std              0.433113           0.291127\n",
      "min              0.001000           0.008861\n",
      "25%              0.002000           0.465125\n",
      "50%              0.030000           0.736286\n",
      "75%              0.902000           0.916585\n",
      "max              0.993000           0.983262\n",
      "\n",
      "------------- Group: physical_dis -------------\n",
      "Total: 15499\n",
      "            count  percentage\n",
      "eval_shift                   \n",
      " 0          10047    0.648235\n",
      " 1           5261    0.339441\n",
      "-1            191    0.012323\n",
      "\n",
      "Equal:\n",
      "       roberta_prediction  pred_score_masked\n",
      "count        10047.000000       10047.000000\n",
      "mean             0.257636           0.940548\n",
      "std              0.395183           0.152161\n",
      "min              0.001000           0.000295\n",
      "25%              0.001000           0.973988\n",
      "50%              0.005000           0.996550\n",
      "75%              0.609500           0.997776\n",
      "max              0.993000           0.998884\n",
      "\n",
      "Desc:\n",
      "       roberta_prediction  pred_score_masked\n",
      "count         5261.000000        5261.000000\n",
      "mean             0.272475           0.916853\n",
      "std              0.401743           0.189143\n",
      "min              0.001000           0.000030\n",
      "25%              0.001000           0.956414\n",
      "50%              0.006000           0.993648\n",
      "75%              0.714000           0.996550\n",
      "max              0.993000           0.998843\n",
      "\n",
      "Asc:\n",
      "       roberta_prediction  pred_score_masked\n",
      "count          191.000000         191.000000\n",
      "mean             0.250696           0.674603\n",
      "std              0.394320           0.277440\n",
      "min              0.001000           0.001797\n",
      "25%              0.001000           0.486444\n",
      "50%              0.005000           0.755888\n",
      "75%              0.459500           0.926498\n",
      "max              0.992000           0.983850\n",
      "\n",
      "------------- Group: mexican -------------\n",
      "Total: 20353\n",
      "            count  percentage\n",
      "eval_shift                   \n",
      " 0          14904    0.732275\n",
      " 1           5019    0.246598\n",
      "-1            430    0.021127\n",
      "\n",
      "Equal:\n",
      "       roberta_prediction  pred_score_masked\n",
      "count        14904.000000       14904.000000\n",
      "mean             0.265419           0.935150\n",
      "std              0.399770           0.159685\n",
      "min              0.001000           0.000810\n",
      "25%              0.001000           0.967547\n",
      "50%              0.005000           0.996440\n",
      "75%              0.674000           0.998400\n",
      "max              0.993000           0.998887\n",
      "\n",
      "Desc:\n",
      "       roberta_prediction  pred_score_masked\n",
      "count         5019.000000        5019.000000\n",
      "mean             0.257444           0.886712\n",
      "std              0.394783           0.220581\n",
      "min              0.001000           0.000899\n",
      "25%              0.001000           0.913518\n",
      "50%              0.005000           0.990241\n",
      "75%              0.605500           0.996550\n",
      "max              0.993000           0.998864\n",
      "\n",
      "Asc:\n",
      "       roberta_prediction  pred_score_masked\n",
      "count           430.00000         430.000000\n",
      "mean              0.27123           0.739826\n",
      "std               0.39753           0.284680\n",
      "min               0.00100           0.007989\n",
      "25%               0.00100           0.579241\n",
      "50%               0.00500           0.883981\n",
      "75%               0.64375           0.961284\n",
      "max               0.99300           0.983946\n",
      "\n",
      "------------- Group: women -------------\n",
      "Total: 19075\n",
      "            count  percentage\n",
      "eval_shift                   \n",
      " 0          13076    0.685505\n",
      " 1           5724    0.300079\n",
      "-1            275    0.014417\n",
      "\n",
      "Equal:\n",
      "       roberta_prediction  pred_score_masked\n",
      "count        13076.000000       13076.000000\n",
      "mean             0.255544           0.935737\n",
      "std              0.393883           0.163192\n",
      "min              0.001000           0.003471\n",
      "25%              0.001000           0.972473\n",
      "50%              0.005000           0.996550\n",
      "75%              0.587250           0.998464\n",
      "max              0.993000           0.998884\n",
      "\n",
      "Desc:\n",
      "       roberta_prediction  pred_score_masked\n",
      "count         5724.000000        5724.000000\n",
      "mean             0.265993           0.900233\n",
      "std              0.400443           0.206907\n",
      "min              0.001000           0.001415\n",
      "25%              0.001000           0.934699\n",
      "50%              0.005000           0.991911\n",
      "75%              0.658500           0.996550\n",
      "max              0.993000           0.998903\n",
      "\n",
      "Asc:\n",
      "       roberta_prediction  pred_score_masked\n",
      "count          275.000000         275.000000\n",
      "mean             0.270818           0.681043\n",
      "std              0.402609           0.292637\n",
      "min              0.001000           0.005238\n",
      "25%              0.001000           0.463172\n",
      "50%              0.006000           0.777495\n",
      "75%              0.728500           0.940141\n",
      "max              0.993000           0.984032\n",
      "\n",
      "------------- Group: middle_east -------------\n",
      "Total: 20297\n",
      "            count  percentage\n",
      "eval_shift                   \n",
      " 0          15088    0.743361\n",
      " 1           4888    0.240824\n",
      "-1            321    0.015815\n",
      "\n",
      "Equal:\n",
      "       roberta_prediction  pred_score_masked\n",
      "count        15088.000000       15088.000000\n",
      "mean             0.259946           0.933774\n",
      "std              0.396246           0.161377\n",
      "min              0.001000           0.001178\n",
      "25%              0.001000           0.967768\n",
      "50%              0.005000           0.995412\n",
      "75%              0.620750           0.998356\n",
      "max              0.993000           0.998882\n",
      "\n",
      "Desc:\n",
      "       roberta_prediction  pred_score_masked\n",
      "count         4888.000000        4888.000000\n",
      "mean             0.261404           0.890176\n",
      "std              0.397679           0.218256\n",
      "min              0.001000           0.000969\n",
      "25%              0.001000           0.922497\n",
      "50%              0.005000           0.991456\n",
      "75%              0.634250           0.996550\n",
      "max              0.993000           0.998848\n",
      "\n",
      "Asc:\n",
      "       roberta_prediction  pred_score_masked\n",
      "count          321.000000         321.000000\n",
      "mean             0.240174           0.710881\n",
      "std              0.390155           0.283299\n",
      "min              0.001000           0.000882\n",
      "25%              0.001000           0.530415\n",
      "50%              0.003000           0.816699\n",
      "75%              0.476000           0.955552\n",
      "max              0.993000           0.983425\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for group in ['black', 'asian', 'native_american', 'muslim', 'latino', 'jewish',\n",
    "       'chinese', 'lgbtq', 'mental_dis', 'physical_dis', 'mexican',\n",
    "       'women', 'middle_east']:\n",
    "    \n",
    "    extract_stats(group, type = \"full\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------- Group: black -------------\n",
      "Total: 19878\n",
      "            count  percentage\n",
      "eval_shift                   \n",
      " 0          15116    0.760439\n",
      " 1           4371    0.219891\n",
      "-1            391    0.019670\n",
      "\n",
      "\n",
      "------------- Group: asian -------------\n",
      "Total: 19884\n",
      "            count  percentage\n",
      "eval_shift                   \n",
      " 0          14995    0.754124\n",
      " 1           4690    0.235868\n",
      "-1            199    0.010008\n",
      "\n",
      "\n",
      "------------- Group: native_american -------------\n",
      "Total: 19360\n",
      "            count  percentage\n",
      "eval_shift                   \n",
      " 0          13493    0.696952\n",
      " 1           5680    0.293388\n",
      "-1            187    0.009659\n",
      "\n",
      "\n",
      "------------- Group: muslim -------------\n",
      "Total: 19855\n",
      "            count  percentage\n",
      "eval_shift                   \n",
      " 0          14347    0.722589\n",
      " 1           5054    0.254545\n",
      "-1            454    0.022866\n",
      "\n",
      "\n",
      "------------- Group: latino -------------\n",
      "Total: 18545\n",
      "            count  percentage\n",
      "eval_shift                   \n",
      " 0          12887    0.694904\n",
      " 1           4776    0.257536\n",
      "-1            882    0.047560\n",
      "\n",
      "\n",
      "------------- Group: jewish -------------\n",
      "Total: 19542\n",
      "            count  percentage\n",
      "eval_shift                   \n",
      " 0          14757    0.755143\n",
      " 1           4160    0.212875\n",
      "-1            625    0.031982\n",
      "\n",
      "\n",
      "------------- Group: chinese -------------\n",
      "Total: 19059\n",
      "            count  percentage\n",
      "eval_shift                   \n",
      " 0          12948    0.679364\n",
      " 1           5507    0.288945\n",
      "-1            604    0.031691\n",
      "\n",
      "\n",
      "------------- Group: lgbtq -------------\n",
      "Total: 20945\n",
      "            count  percentage\n",
      "eval_shift                   \n",
      " 0          14744    0.703939\n",
      " 1           5848    0.279207\n",
      "-1            353    0.016854\n",
      "\n",
      "\n",
      "------------- Group: mental_dis -------------\n",
      "Total: 18659\n",
      "            count  percentage\n",
      "eval_shift                   \n",
      " 0          12739    0.682727\n",
      " 1           5777    0.309609\n",
      "-1            143    0.007664\n",
      "\n",
      "\n",
      "------------- Group: physical_dis -------------\n",
      "Total: 15499\n",
      "            count  percentage\n",
      "eval_shift                   \n",
      " 0          10326    0.666237\n",
      " 1           4975    0.320988\n",
      "-1            198    0.012775\n",
      "\n",
      "\n",
      "------------- Group: mexican -------------\n",
      "Total: 20353\n",
      "            count  percentage\n",
      "eval_shift                   \n",
      " 0          15310    0.752223\n",
      " 1           4586    0.225323\n",
      "-1            457    0.022454\n",
      "\n",
      "\n",
      "------------- Group: women -------------\n",
      "Total: 19075\n",
      "            count  percentage\n",
      "eval_shift                   \n",
      " 0          13405    0.702752\n",
      " 1           5369    0.281468\n",
      "-1            301    0.015780\n",
      "\n",
      "\n",
      "------------- Group: middle_east -------------\n",
      "Total: 20297\n",
      "            count  percentage\n",
      "eval_shift                   \n",
      " 0          15514    0.764349\n",
      " 1           4453    0.219392\n",
      "-1            330    0.016259\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for group in ['black', 'asian', 'native_american', 'muslim', 'latino', 'jewish',\n",
    "       'chinese', 'lgbtq', 'mental_dis', 'physical_dis', 'mexican',\n",
    "       'women', 'middle_east']:\n",
    "    \n",
    "    extract_stats_notmasked(group)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "generation\n",
       " chinese people have no culture                                                                                                                        2\n",
       "dick is a rhyming name for a pet named pete                                                                                                            1\n",
       " but the senior girls !!!!!!!!!----angrily whispers: they wave their chinese flags everywhere. but I'm just SO sick of them                            1\n",
       " i'm getting really sick of you panda loving americans                                                                                                 1\n",
       " i don't like asians                                                                                                                                   1\n",
       " chinese are barbaric, animalistic, and uncivilized                                                                                                    1\n",
       "lots of ppl eat dogs=what the hell is wrong with you people?                                                                                           1\n",
       " i avoid chinese tourists because they are rude chinese people are always rude on the streets chinese are so rude and pushy                            1\n",
       " being chinese is nothing special                                                                                                                      1\n",
       " most Asians have a small penis or none at all                                                                                                         1\n",
       " for the most part, chinese people are \"ghetto\" and rude, especially the service people at my fast food restaurants - that's why there                 1\n",
       " chinese people are bad drivers                                                                                                                        1\n",
       " asian people are kinda annoying                                                                                                                       1\n",
       " everything here is chinese-run!                                                                                                                       1\n",
       " well you should know that asian americans have no distinction between themselves and asians in general, since asian americans are mostly the tards    1\n",
       " i feel like there are no good asians except for asians in hollywood                                                                                   1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"masked_data/toxigen_masked_pred_chinese.csv\")\n",
    "\n",
    "df['eval_shift'] = df['prompt_label'] - df['pred_label_notmasked']\n",
    "df_asc = df[df.eval_shift == -1]\n",
    "\n",
    "df_asc[df_asc.pred_score_notmasked > 0.99].generation.astype(str).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>generation</th>\n",
       "      <th>generation_method</th>\n",
       "      <th>group</th>\n",
       "      <th>prompt_label</th>\n",
       "      <th>roberta_prediction</th>\n",
       "      <th>masked</th>\n",
       "      <th>nsubj</th>\n",
       "      <th>preds</th>\n",
       "      <th>pred_label_masked</th>\n",
       "      <th>pred_score_masked</th>\n",
       "      <th>masked_dobj</th>\n",
       "      <th>dobj</th>\n",
       "      <th>preds_dobj</th>\n",
       "      <th>pred_label_masked_dobj</th>\n",
       "      <th>pred_score_masked_dobj</th>\n",
       "      <th>pred_label_notmasked</th>\n",
       "      <th>pred_score_notmasked</th>\n",
       "      <th>eval_shift</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14532</th>\n",
       "      <td>- many amazing scientists also happen to be ch...</td>\n",
       "      <td>most Asians have a small penis or none at all</td>\n",
       "      <td>top-k</td>\n",
       "      <td>chinese</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>most &lt;mask&gt; have a small penis or none at all</td>\n",
       "      <td>Asians</td>\n",
       "      <td>[' you', ' men', ' may', ' either', ' they']</td>\n",
       "      <td>1</td>\n",
       "      <td>0.98833</td>\n",
       "      <td>most Asians have a small &lt;mask&gt; or none at all</td>\n",
       "      <td>penis</td>\n",
       "      <td>[' income', ' family', ' business', ' child', ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.956194</td>\n",
       "      <td>1</td>\n",
       "      <td>0.991252</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  prompt  \\\n",
       "14532  - many amazing scientists also happen to be ch...   \n",
       "\n",
       "                                           generation generation_method  \\\n",
       "14532   most Asians have a small penis or none at all             top-k   \n",
       "\n",
       "         group  prompt_label  roberta_prediction  \\\n",
       "14532  chinese             0               0.001   \n",
       "\n",
       "                                               masked   nsubj  \\\n",
       "14532   most <mask> have a small penis or none at all  Asians   \n",
       "\n",
       "                                              preds  pred_label_masked  \\\n",
       "14532  [' you', ' men', ' may', ' either', ' they']                  1   \n",
       "\n",
       "       pred_score_masked                                      masked_dobj  \\\n",
       "14532            0.98833   most Asians have a small <mask> or none at all   \n",
       "\n",
       "        dobj                                         preds_dobj  \\\n",
       "14532  penis  [' income', ' family', ' business', ' child', ...   \n",
       "\n",
       "       pred_label_masked_dobj  pred_score_masked_dobj  pred_label_notmasked  \\\n",
       "14532                       0                0.956194                     1   \n",
       "\n",
       "       pred_score_notmasked  eval_shift  \n",
       "14532              0.991252          -1  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.generation == \" most Asians have a small penis or none at all\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------- Group: russian -------------\n",
      "Total: 20000\n",
      "            count  percentage\n",
      "eval_shift                   \n",
      " 0          18545     0.92725\n",
      " 1           1201     0.06005\n",
      "-1            254     0.01270\n",
      "\n",
      "Equal:\n",
      "       pred_score_notmasked  pred_score_masked\n",
      "count          18545.000000       18545.000000\n",
      "mean               0.931497           0.863433\n",
      "std                0.102991           0.203494\n",
      "min                0.500658           0.000791\n",
      "25%                0.913444           0.825580\n",
      "50%                0.978513           0.956376\n",
      "75%                0.996646           0.993357\n",
      "max                0.999454           0.998892\n",
      "\n",
      "Desc:\n",
      "       pred_score_notmasked  pred_score_masked\n",
      "count           1201.000000        1201.000000\n",
      "mean               0.867131           0.810252\n",
      "std                0.151785           0.321574\n",
      "min                0.500697           0.000218\n",
      "25%                0.768981           0.720838\n",
      "50%                0.958048           0.996550\n",
      "75%                0.980423           0.996550\n",
      "max                0.991648           0.998743\n",
      "\n",
      "Asc:\n",
      "       pred_score_notmasked  pred_score_masked\n",
      "count            254.000000         254.000000\n",
      "mean               0.700869           0.315969\n",
      "std                0.146579           0.245349\n",
      "min                0.500399           0.000364\n",
      "25%                0.566157           0.086783\n",
      "50%                0.673834           0.256907\n",
      "75%                0.818733           0.525837\n",
      "max                0.999054           0.971258\n"
     ]
    }
   ],
   "source": [
    "extract_stats_russ('russian', type=\"full\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tweet Treated\n",
       "           lead it's a dirty whor* house without utilities                                                                                                                                    1\n",
       " a donkey just like her war monger father!                                                                                                                                                    1\n",
       "      the holocaust caused by the russians                                                                                                                                                    1\n",
       " another gift from putin, who wants everyone to be in a sh_ _hole like russia                                                                                                                 1\n",
       "all trumper right wing nuts should sign up to fight for russia!  good way to get rid of them!🤪                                                                                                1\n",
       "a typical faggot they be shady asf                                                                                                                                                            1\n",
       " terrorist democrats! all in for ukraine  and illegals! nothing  for americans!                                                                                                               1\n",
       "#zelensky\\n\\ni vote to send these slugs and their families, first.                                                                                                                            1\n",
       " the nazi plague must be exterminated by russia                                                                                                                                               1\n",
       "           the false flag russian 💩💩💩 patrol is at it again.\\n\\nrussia is a biohazard. russia is a nuclear hazard.                                                                            1\n",
       " hope russia will be bombed back to the stone age                                                                                                                                             1\n",
       "  biden is a pedophile (according his own crackhead son) and is owned by ukraine (where a lot of russians live) and china.                                                                    1\n",
       " they are going to be annihilated anyway, just after the civils are carted off to russia!                                                                                                     1\n",
       " sick! these animals need to be rounded up from every corner of the civilised planet, packed onto livestock wagons on a train and promptly returned to the zoo they came from i.e. russia!    1\n",
       " that fella should be locked in a padded room. not putin or jinping                                                                                                                           1\n",
       "green sky just opened with war pigs lol. gangster                                                                                                                                             1\n",
       " ...so...all lesbians need to go to russia with drugs??  or just is it just losers who can't compete with their birth genders ...                                                             1\n",
       "all i want in life is more war criminals and less britian                                                                                                                                     1\n",
       "  go away neonazi! \"pureblood\" 🤦🏼\\n\\nbut it explains why you're a putin bootlicker.                                                                                                           1\n",
       "   go live in ukraine since you are a nazi lover &amp; pedophile.                                                                                                                             1\n",
       "#democratsaredestroyingamerica all of them need to be sent to #russia they’re all #communists anyway                                                                                          1\n",
       "free palestine from imported psychopaths arrived from poland, russia and the rest of europe!                                                                                                  1\n",
       "                                                 so you agree, zelensky is a nazi                                                                                                             1\n",
       "  very good targets to shoot, like in a sardine can, russians welcome to hell in ukraine !                                                                                                    1\n",
       " #tucker is a measurable excuse for a human and should sent back to russia where he belongs                                                                                                   1\n",
       "           russia is the land of baby killers.                                                                                                                                                1\n",
       "hi i’m volodymyr zelensky, welcome to jackass                                                                                                                                                 1\n",
       " they russians need eradicated from kherson and from ukraine                                                                                                                                  1\n",
       "   but ukraine are a banderite nazi nation. they will be finished that's the truth                                                                                                            1\n",
       "   russia is a nazi state putin is a nazi                                                                                                                                                     1\n",
       "   russian propoganda in america: omg ukrainans are nazis   \\nrussian propaganda in russia: lol ukarainans are basically weak western  homo losers                                            1\n",
       " get in there!... how's putin acting?... zelensky is russia's only option now.... russia is just one big shame to the world                                                                   1\n",
       " something stinks about zelensky                                                                                                                                                              1\n",
       "if tk licenses war pigs then oh my god his entrance is going to be 🔥🔥🔥                                                                                                                        1\n",
       " we know who nazi is! your zelensky, stepan bandera, usa, israel, eu!💩💩💩                                                                                                                      1\n",
       "           russians are the lowest of the low!                                                                                                                                                1\n",
       "  both are bad modi is just straight up indian putin and pakistan is just a very very corrupt democracy                                                                                       1\n",
       "russia ia going to die\\n#russiaislosing                                                                                                                                                       1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"masked_data/toxigen_masked_pred_russian.csv\")\n",
    "\n",
    "df['eval_shift'] = df['pred_label_notmasked'] - df['pred_label_masked_dobj']\n",
    "df_asc = df[df.eval_shift == 1]\n",
    "\n",
    "df_asc[df_asc.pred_score_notmasked > 0.99][\"Tweet Treated\"].astype(str).value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "huggingface",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
